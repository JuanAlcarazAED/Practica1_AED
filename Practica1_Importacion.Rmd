---
title: "Práctica 1. Importación de Datos"
subtitle: "Análisis Exploratorio de Datos, Máster en Ciencia de Datos - UV"
output:
  html_document:
    echo: yes
    number_sections: yes
    theme: lumen
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, cache=F, echo=F, message=F, warning=F, tidy=F}
# CONFIGURACION GENERAL
library(knitr)
options(width=100)
# Opciones generales chunks: usar include=F para generar sin código R
opts_chunk$set(echo=T, message=F, error=F, warning=T, comment=NA,
               fig.align='center', dpi=100, tidy=F, cache.path='.cache/',
               fig.path='./figure/')
knit_hooks$set(inline=function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse=', ')
  }
})
```

# Introducción

El objetivo de esta práctica es realizar la importación de ficheros con diferentes formatos, organizar los datos en un **data frame**, y almacenarlo en un fichero tipo **RData**. Los ficheros a importar son los siguientes:

1.  `DFP1_11122015 124700.csv ———————————————————————> Deposito.RData`
2.  `“Transactions from a Bakery” (Kaggle) ——————————> BreadBasket.RData`
3.  `(SPSS) PsychBike.sav ———————————————————————————> PsychBike.RData`
4.  `FileCodificado.json ————————————————————————————> FileCodificado.RData`
5.  `ERCA.xls ———————————————————————————————————————> ERCA.RData`
6.  `subjectInfo.xlsx ———————————————————————————————> Pacientes.RData`

## Crea un proyecto

Para cada práctica crea un nuevo proyecto con:

-   Una carpeta `./data` que contenga los datos.
-   Opcionalmente, otra carpeta `./figure` para las figuras.
-   Opcionalmente, otras para organizar la información, `./program`, etc.

## Rutas locales

Usa siempre rutas referidas a la carpeta, en la que se encuentra el fichero fuente, y siempre rutas *relativas* a dicha ubicación. Ejemplos:

-   `ruta1 <- 'data/tabla1.txt'`: Fichero en la carpeta datos del directorio donde está el código.
-   `ruta2 <- '../data/tabla1.txt'`: Fichero en la carpeta datos que cuelga de un nivel superior.
-   `ruta3 <- '../../data/tabla1.txt'`: Fichero en la carpeta datos que cuelga de dos niveles superiores.
-   `ruta4 <-'C:/MisDatos/Ej.txt'`: **NO USAR NUNCA RUTAS ABSOLUTAS**.

# Ejemplo: fichero *DFP1_11122015 124700.csv*

## Importación del fichero

1.  Usar la herramienta de importación para previsualizar el resultado final. Compara las opciones *base* y *readr*.
2.  Leer el fichero con `read.csv` y el parámetro `stringsAsFactors=F`.
3.  Convertir fecha y hora con `as.POSIXlt` y `as.hms` (`hms` library).
4.  Almacenar con `save`.

```{r}
fname <- 'data/DFP1_11122015 124700.csv'

ruta_local <- "./data/DFP1_11122015 124700.csv"

# Importamos con la herramienta de previsualización
DFP1_11122015.124700_A <- read.delim("./data/DFP1_11122015 124700.csv")

# Ahora con la función read.csv
DFP1_11122015.124700_B <- read.csv(file = ruta_local, stringsAsFactors = F, sep="\t")

# Convertimos las fechas en texto ha fechas de verdad
DFP1_11122015.124700_A$FECHA <- as.POSIXlt(DFP1_11122015.124700_A$FECHA, format = "%d/%m/%Y")

```

```{r}
# Debemos importar una librería, la hms
library("hms")
```

```{r}
# Almacenamos las horas como horas y no como texto
DFP1_11122015.124700_A$HORA <- hms::as_hms(DFP1_11122015.124700_A$HORA)

# Guardamos la tabla modificada en un fichero
nombre_Fichero <- "DFP1_11122015.124700_Modificada"
file.create("DFP1_11122015.124700_Modificada")
save(DFP1_11122015.124700_A, file = nombre_Fichero, ascii = T)
```

## Inspección de los datos

Inspecciona los datos con `str`, `head`, `tail` y `summary`.

```{r}
# str, head, tail, summary
str(DFP1_11122015.124700_A)
summary(DFP1_11122015.124700_A)

n = 5
head(DFP1_11122015.124700_A, n)
tail(DFP1_11122015.124700_A, n)
```

# Fichero *Transactions from a Bakery* (Kaggle)

## Importación del fichero

Una vez hemos descargado el fichero podríamos leerlo con `read.csv` y transformar los datos a los tipos correctos.

Otra opción es usar la librería `readr` para especificar directamente el tipo de datos.

1.  Utiliza *Import Dataset* de RStudio, opción *readr*, para previsualizar el fichero y especificar los tipos de datos.
2.  Copia el código resultante y comprueba la lectura de datos.
3.  Guarda el data frame con `save`.

```{r}
library(readr)

BreadBasket_DMS <- read_csv("data/BreadBasket_DMS.csv", 
    col_types = cols(Date = col_date(format = "%Y-%m-%d"), 
        Time = col_time(format = "%H:%M:%S")))

file.create(file = "BreadBasket")
save(BreadBasket_DMS, file = "BreadBasket", ascii = T)
```

## Inspección de los datos

Inspecciona los datos con `str`, `head`, `tail` y `summary`.

```{r}
# dim, str, ...
str(BreadBasket_DMS)
summary(BreadBasket_DMS)
n <- 5
head(BreadBasket_DMS, n)
tail(BreadBasket_DMS, n)
```

# Fichero SPSS *PsychBike.sav*

## Importación del fichero

Intenta descargar el fichero directamente desde la ruta [http://staff.bath.ac.uk/pssiw/stats2](http://staff.bath.ac.uk/pssiw/stats2/) Podemos leer ficheros de IBM SPSS mediante la librería `haven`.

1.  Leer el fichero con `read_sav`.
2.  Guardar el data frame con `save`.

```{r}
library(haven)

PyschBike <- read_sav(file = "./data/PsychBike.sav")
file.create(file = "Pysch_Bike")
save(PyschBike, file = "Pysch_Bike", ascii = T)
```

## Inspección de los datos

Inspecciona los datos con `str`, `head`, `tail` y `summary`.

```{r}
# dim, str, etc.
str(PyschBike)
summary(PyschBike)
n <- 5
head(PyschBike, n)
tail(PyschBike, n)
```

# Fichero JSON *FileCodificado.json*

## Importación del fichero

Los ficheros JSON (*JavaScript Object Notation*) son ficheros de texto que contienen datos (originalmente presentaciones de objetos JavaScript). Es un formato muy popular que se utiliza frecuentemente como alternativa a los ficheros XML, puesto que son más fáciles de leer e interpretar.

En R podemos importar ficheros JSON con la librería `jsonlite`. Las funciones más empleadas son:

-   `read_json` y `write_json`: leen/escriben objetos R directamente de/en ficheros JSON.
-   `toJSON`: obtiene una representación JSON de un objeto R.
-   `fromJSON`: inversa de la anterior, convierte una representación JSON en un objeto R.

## Importar el fichero `FileCodificado.json`

1.  Abrir el fichero `FileCodificado.json` con un editor de texto (el de RStudio vale) para ver qué contiene. Comprobaremos que se puede leer e interpretar con facilidad.
2.  Importar el fichero a R con `read_json`. Observar la importancia del parámetro `simplifyVector`.
3.  Como alternativa, leer el fichero en modo texto con `read_file` de la librería **readr** y después convertir el objeto character a data frame con `fromJSON`.
4.  Almacenar los resultados en `FileCodificado.RData`.

```{r}
library(jsonlite)
filename <- 'data/FileCodificado.json'

# El argumento symplifyVector sirve para que los datos se transforme en un dataframe o un vector, se trata de un argumento que por defecto toma el valor FALSE, pero si lo dejamos así al importar
FicheroCodificado <- read_json("./data/FileCodificado.json")
# El resultado es una lista, donde cada elemento es un registro.Esto no es lo que queremos.
# Repetimos pero ahora cambiando el valor del parámetro
FicheroCodificado1 <- read_json("./data/FileCodificado.json", simplifyVector = T)
```

```{r}
# Ahora vamos a explorar otra posibilidad

# Se carga el contenido literal contenido en el fichero
textoJSON <- read_file(file = "./data/FileCodificado.json")
# Se utiliza una unción para traducir del lenguaje usado por un json, para extraer los datos y pasarlos a un dataframe
FicheroCodificado_2 <- fromJSON(textoJSON)
```

**NO HACER NUNCA `x <- load("File.Rdata")`**

## Inspección de los datos

Inspecciona los datos con `str`, `head`, `tail` y `summary`.

```{r}
# str, head, tail, summary
str(FicheroCodificado_2)
summary(FicheroCodificado_2)
n <- 5
head(FicheroCodificado_2, n)
tail(FicheroCodificado_2, n)
```

## Extra: exportar datos en formato JSON

Es importante saber cómo exportar datos en este formato.

1.  Almacenar el dataset `iris` en disco con `write_json`. Abrir el fichero con RStudio y comprobar el resultado.
```{r}
file.create("Iris_JSON")
write_json(iris, "./Iris_JSON")
```
Se observa que el fichero creado se guarda con el mismo formato visto para el conjunto del apartado anterior, en el que cada registro o sujeto se guarda entre llaves con los nombre de cada variable y el vahlor de estas para el registro. Similar a los diccionarios de Python.

2.  Como alternativa, obtener la representación JSON de los datos con `toJSON` y luego almacenarlos con `write_file`. Observar la diferencia de usar o no el parámetro `pretty` en `toJSON`.

```{r}
# 
file.create("iris_formato_JSON")
texto <- toJSON(iris)
write_file(texto, file = "./iris_formato_JSON")

file.create("iris_formato_JSON_pretty")
texto_pretty <- toJSON(iris, pretty = T)
write_file(texto_pretty, file = "./iris_formato_JSON_pretty")
```
La diferencia entre usar el parámetro `pretty` o no, es que el texto se dispone de forma mucho más legible en el documento, sin esta opción toda la información se coloca sin espacios en una sola fila del archivo.

# Fichero *ERCA.xlsx*

## Importación del fichero

-   Abrir el excel para ver qué pinta tiene.
-   Como el fichero es muy irregular la función de importación `read_excel` no es capaz de detectar automáticamente los tipos de datos y lo lee todo como caracteres (strings).
-   Fechas: las importa como un string que interpretado como `numeric` es el número de días transcurridos desde 01-01-1900.
-   Si se indica en `col_type` que son `date` los lee bien.
-   Formatos numéricos: se puede indicar el tipo en `col_type`, o convertirlos después con `as.numeric`.
-   Guardar datos en formato .RData.

```{r warning=F}
library(readxl)
fname <- "data/ERCA.xlsx"

# Usaremos la función read_excel de readxl
df <- read_excel(fname, sheet=2, col_types = c("numeric", "text", "date", "text", "date", rep("guess", 58-5))) # El formato de las fechas no es correcto
df
Columnas_date <- c("FECHA NAC", "FECHA ENTRADA", "FECHA SALIDA", "FECHA CONTROL")
Columnas_numeric <-  c("COL", "TG", "HIDROF", "ANTI", "DIURET", "IECAS", "PESO", "TALLA", "HB","IST", "FERRITINA", "UREA", "FOSFORO", "CALCIO", "CICALCET", "QUELANTES","PTH", "BICARBO", "ALOPURIN", "URICO", "PROTEINU", "ALBUMI", "sodio", "potasio", "cloro", "HB GLIC", "GLUCOSA", "PCR")


# Es más fácil ver cuales NO son 'numeric'.
ct <- rep(1, length(colnames(df)))
names(ct) <-  colnames(df)

for (name in names(ct)){
  if (name %in% Columnas_date){
    ct[name] <- "date"
  } else if (name %in% Columnas_numeric){
    ct[name] <- "numeric"
  }else{
    ct[name] <- "guess" 
  }
}

# Definir los tipos de datos en 'ct' y releer con 'read_excel'.
df_2 <- read_excel(fname, sheet=2, col_types=ct)
df_2
```

```{r}
file.create("./Datos_Dialisis")
save(df_2, file = "./Datos_Dialisis",ascii = T)
```

## Inspección de los datos

-   Utiliza las funciones `head`, `tail`, `str` y `summary` para inspeccionar el fichero.
-   Limpia el data frame descartando las filas con `NA` en la primera columna (`IDENTIFICA`).

```{r}
# Conviene limpiar primero un poco => eliminar is.na, etc.
df[!is.na(df[1]),1]
df[!is.na(df[1]),]
# Se puede hacer mejor y quitar todas las instancias con NA

# head, tail, str, summary
str(df)
summary(df)
n <- 5
head(df, n)
tail(df, n)
```

# Fichero *subjectInfo.xlsx*

## Importación del fichero

1.  Leer cada hoja (hasta 4) en data frames separados (`Hoja1`, `Hoja2`, ...) usando `read_excel` y el parámetro `sheet`.
```{r}
filename <- "data/subjectInfo.xlsx"
library(readxl)
subjectInfo_Hoja1 <- read_excel("data/subjectInfo.xlsx", sheet = 1)
subjectInfo_Hoja2 <- read_excel("data/subjectInfo.xlsx", sheet = 2)
subjectInfo_Hoja3 <- read_excel("data/subjectInfo.xlsx", sheet = 3)
subjectInfo_Hoja4 <- read_excel("data/subjectInfo.xlsx", sheet = 4)
```

2.  Leer todas las hojas automáticamente usando:
    -   Usando `excel_sheets`: obtén los nombres de las hojas del fichero excel y guardalos en la variable `sheets`.
    
```{r}
nombres_Hojas = excel_sheets("data/subjectInfo.xlsx")
```

    -   Usando un bucle `for` sobre los nombres devueltos por `excel_sheets`. Guardamos sobre una lista creada con `df <- list()` y añadiendo nuevos elementos con `df[[n]]`, donde `n` es una variable numérica entera o carácter (ojo al doble corchete).

```{r}
df <- list()
n <- 1
for (nombre in nombres_Hojas){
  df[[n]] <- read_excel("data/subjectInfo.xlsx", sheet = nombre)
  n <- n+1
}
```

3.  En lugar de un bucle for usa `lapply`
    -   Recuerda que `lapply` aplica una función a todos los elementos de un vector o lista y devuelve **una lista** con los resultados obtenidos.
    -   Hay que definir una función que llame a `read_excel` y que tome como parámetro la hoja a leer.

```{r}
Importar_Hoja_Excel <- function(nombre_Hoja, nombre_Archivo_Excel = "data/subjectInfo.xlsx"){
  return(read_excel(nombre_Archivo_Excel, sheet = nombre_Hoja))
}

Hojas <- lapply(nombres_Hojas, Importar_Hoja_Excel)
```

    -   La lista de devuelta por `lapply` no tiene nombres. Podemos nombrar esta lista con `names(x) <- sheets`, donde `x` es la lista obtenida con `lapply`, y `sheets` los nombres de las hojas obtenidas con excel_sheets\`.
  
```{r}
names(Hojas) <- nombres_Hojas
```

    
4.  Como siempre al final guardamos el resultado con `save`.

```{r}
file.create("Informacion_Sujetos")
save(Hojas, file = "Informacion_Sujetos")
```

## Inspección de los datos

Inspecciona los datos con `str` (jugar con `max.level`), `head`, `tail` y `summary`.

```{r}
# Con max.level, le podemos decir que nos de la estructura de los elementos de la lista
str(Hojas, max.level = 3)
n <- 5
for (tabla in Hojas){
  print("----------------------------")
  print(summary(tabla))
  head(tabla, n)
  tail(tabla, n)
}



```
